{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3dac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "from tqdm.notebook import  tqdm\n",
    "from IPython.display import display as print\n",
    "# import importlib\n",
    "# importlib.reload(core)\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from core_lib import MyDataset, plot_dataset, r2_loss,get_predict_ks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29406f27-1b18-48db-b15d-fc9a238847ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k10,k_kinetics,xNH3_r2,xNO3_r2,xNO2_r2,xNOrg_r2,xN2_r2,ANH3_r2,ANO3_r2,ANO2_r2,ANOrg_r2,AN2_r2,r2_mean,r2_all'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "res_path_list = glob.glob(\"saved_idata-v2/*\")\n",
    "dataset = MyDataset(\"dataset/data.csv\")\n",
    "df = dataset.get_df()\n",
    "cct_names, error_names = dataset.get_var_col_names()\n",
    "\n",
    "\n",
    "title_str = \"k10,k_kinetics\"\n",
    "\n",
    "for c_name in cct_names:\n",
    "    title_str += f\",{c_name}_r2\"\n",
    "    \n",
    "title_str += \",r2_mean,r2_all\"\n",
    "\n",
    "print(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79615bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16666667e+00, 2.39880952e+00, 3.11000000e-02, 6.22850000e+01,\n",
       "       7.11000000e-05, 7.94863498e+00, 6.85792330e-02, 7.23100000e-02,\n",
       "       9.85666700e-03, 8.32000000e-03])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  0.5,  48. ,  96. , 144. ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_path_list = glob.glob(\"saved_idata-v2/*\")\n",
    "dataset = MyDataset(\"dataset/data.csv\")\n",
    "df = dataset.get_df()\n",
    "cct_names, error_names = dataset.get_var_col_names()\n",
    "c0 = df[cct_names].values[0]\n",
    "t_eval = df['time'].values\n",
    "\n",
    "print(c0)\n",
    "print(t_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fd4f2-2238-44b7-b8e3-f39c0dd005bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path_list = glob.glob(\"saved_idata-v2/*\")\n",
    "\n",
    "dataset_path = \"dataset/data.csv\"\n",
    "dataset = MyDataset(dataset_path)\n",
    "df = dataset.get_df()\n",
    "cct_names, error_names = dataset.get_var_col_names()\n",
    "c0 = df[cct_names].values[0]\n",
    "t_eval = df['time'].values\n",
    "\n",
    "\n",
    "res_csv = open(\"res_r2-v2.csv\", 'w+', encoding=\"utf8\")\n",
    "title_str = \"k10,k_kinetics\"\n",
    "for c_name in cct_names:\n",
    "    title_str += f\",{c_name}_r2\"\n",
    "\n",
    "title_str += \",r2_mean,r2_all\"\n",
    "res_csv.write(f\"{title_str}\\n\")\n",
    "\n",
    "\n",
    "# res_path_list = res_path_list[:2]\n",
    "for index, res_file_path in enumerate(res_path_list):\n",
    "    \n",
    "    print(f\"{index+1}/{len(res_path_list)} {res_file_path}\")\n",
    "    \n",
    "    line_str = \"\"\n",
    "    \n",
    "    k_10 = os.path.basename(res_file_path).split('-')[0]\n",
    "    k_10_2 = bin(int(k_10))[2:]\n",
    "    k_kinetics = f\"{k_10_2:0>11}\"\n",
    "    \n",
    "    line_str += f\"{k_10},{k_kinetics}\"\n",
    "    \n",
    "    f_size = os.path.getsize(res_file_path)\n",
    "    if f_size<1:\n",
    "        continue\n",
    "    \n",
    "    idata = pickle.load(open(res_file_path, 'rb'))\n",
    "    predict_ks = get_predict_ks(idata)\n",
    "\n",
    "    ks, k_kinetics = predict_ks, k_kinetics\n",
    "\n",
    "    _db2 = MyDataset(dataset_path=dataset_path)\n",
    "    _db2.set_as_sim_dataset(t_eval, c0, args=(predict_ks, k_kinetics))\n",
    "    c_df = _db2.get_df()\n",
    "\n",
    "    # core.plot_dataset(dataset, _db2)\n",
    "\n",
    "    r2_losses = []\n",
    "    for cct_name in cct_names:\n",
    "        _l = r2_loss(df[cct_name], c_df[cct_name])\n",
    "        line_str += f\",{_l}\"\n",
    "        r2_losses.append(_l)\n",
    "    r2_all = r2_loss(df[cct_names].values, c_df[cct_names].values)\n",
    "    r2_mean = np.array(r2_losses).mean()\n",
    "    line_str += f\",{r2_mean}, {r2_all}\"\n",
    "    res_csv.write(f\"{line_str}\\n\")\n",
    "\n",
    "res_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f459299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbd2c194b49ea80345e8ea18e3a6000c76ee140cf13f4f15affb9019c7957e43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
