{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98a23c1f",
   "metadata": {},
   "source": [
    "## 未优化，停止使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e72a1a2-d420-4d7b-a6e7-c29e7e89bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from itertools import product\n",
    "import os.path as osp\n",
    "from scipy.optimize import leastsq\n",
    "import time\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.integrate import odeint\n",
    "import math\n",
    "import sunode\n",
    "import sunode.wrappers.as_pytensor\n",
    "from copy import deepcopy\n",
    "\n",
    "# from tqdm import tqdm, trange\n",
    "from tqdm.notebook import  tqdm\n",
    "from IPython.display import display as print\n",
    "from datetime import datetime\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649273c5-7eb4-49ba-9e22-419d8adcf9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(object):\n",
    "\n",
    "    def __init__(self, dataset_path):\n",
    "\n",
    "        self.dataset_path = dataset_path\n",
    "        \n",
    "        df = pd.read_csv(dataset_path)\n",
    "        \n",
    "        self.df = df\n",
    "        self._setup()\n",
    "    \n",
    "    def _setup(self):\n",
    "        \n",
    "        df = self.df\n",
    "        # 数据初步处理\n",
    "        # 计算反应速率rate，初始速率固定设置为0\n",
    "        for c_i, (col_name, col_sr) in enumerate(df.items()):\n",
    "            if \"error\" in col_name or \"time\" in col_name or \"rate\" in col_name:\n",
    "                continue\n",
    "            rate_col_name = f\"{col_name}_rate\"\n",
    "            rates = []\n",
    "            pre_t = None\n",
    "            pre_v = None\n",
    "            for th, (index, value) in zip(df['time'], col_sr.items()):\n",
    "                if int(index) == 0:\n",
    "                    rates.append(0.0)\n",
    "                    pre_t = th\n",
    "                    pre_v = value\n",
    "                    continue\n",
    "\n",
    "                delta_t = th - pre_t\n",
    "                delta_value = value - pre_v\n",
    "                # print(col_name, index, pre_t, th, pre_v ,value)\n",
    "                rates.append(delta_value / delta_t)\n",
    "                pre_t = th\n",
    "                pre_v = value\n",
    "            df[rate_col_name] = rates\n",
    "\n",
    "        # 准备输出值 Y\n",
    "        self.cct_names = []\n",
    "        for x in self.df.columns:\n",
    "            if \"time\" in x or \"error\" in x or \"rate\" in x:\n",
    "                continue\n",
    "            self.cct_names.append(x)\n",
    "        self.rates_names = [f\"{x}_rate\" for x in self.cct_names]\n",
    "        self.error_names = [f\"{x}-error\" for x in self.cct_names]\n",
    "\n",
    "        self.cct = self.df[self.cct_names].values\n",
    "        self.rates = self.df[self.rates_names].values\n",
    "        self.errors = self.df[self.error_names].values\n",
    "    \n",
    "    \n",
    "    def set_as_sim_dataset(self, dcdt_fuc, t_eval, y0, args):\n",
    "        \n",
    "        y = odeint(dcdt_fuc, y0=y0, t=t_eval, args=args)\n",
    "        \n",
    "        # y.shape (size, 10)\n",
    "        df_new = pd.DataFrame(columns=['time'] + self.cct_names)\n",
    "        df_new['time'] = t_eval\n",
    "        \n",
    "        for c_name, col_val in zip(self.cct_names, np.transpose(y, [1,0])):\n",
    "            df_new[c_name] = col_val\n",
    "            df_new[f\"{c_name}-error\"] = 0.001\n",
    "        \n",
    "        self.df = df_new\n",
    "        self._setup()\n",
    "    \n",
    "    def set_dataset(self, c_pred_df):\n",
    "        \n",
    "        df = deepcopy(c_pred_df)\n",
    "        df['time'] = self.df['time'].values\n",
    "        for c_name in self.cct_names:\n",
    "            c_error_name = f\"{c_name}-error\"\n",
    "            n_len = len(df[c_name].values)\n",
    "            _error = np.repeat(0.0001, n_len)\n",
    "            df[c_error_name] = _error\n",
    "        self.df = df\n",
    "        self._setup()\n",
    "\n",
    "\n",
    "    def get_rates(self):\n",
    "        return self.rates\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_errors(self):\n",
    "        return self.errors\n",
    "\n",
    "    def get_cct(self):\n",
    "        return self.cct\n",
    "\n",
    "    def get_var_col_names(self):\n",
    "        return self.cct_names, self.rates_names, self.error_names\n",
    "\n",
    "    def get_weights(self):\n",
    "        max_value = self.df[self.cct_names].describe().loc['max'].values.max()\n",
    "\n",
    "        vars_max = self.df[self.cct_names].describe().loc['max']\n",
    "        weights = (max_value / vars_max).values\n",
    "\n",
    "        return np.array(weights)\n",
    "\n",
    "    def get_vars_max(self):\n",
    "        vars_max = self.df[self.cct_names].describe().loc['max'].values\n",
    "        return vars_max\n",
    "\n",
    "\n",
    "def get_format_time(f_s=None):\n",
    "    haomiao = str(time.time()).split('.')[-1]\n",
    "    if f_s is None:\n",
    "        f_s = \"%Y-%-m-%d %H:%M:%S.\"\n",
    "        return datetime.now().strftime(f_s) + haomiao\n",
    "    return datetime.now().strftime(f_s)\n",
    "def plot_dataset(dataset, dataset_pred=None):\n",
    "    \n",
    "    df = dataset.get_df()\n",
    "    cct_names, error_names = dataset.get_var_col_names()\n",
    "    \n",
    "    cols = 5\n",
    "    rows = math.ceil(len(cct_names) / cols)\n",
    "\n",
    "    fig, fig_axes = plt.subplots(ncols=cols, nrows=rows, figsize=(4.2 * cols, 4 * rows), dpi=100)\n",
    "    if isinstance(fig_axes, np.ndarray):\n",
    "        fig_axes = fig_axes.reshape(-1)\n",
    "    else:\n",
    "        fig_axes = [fig_axes]\n",
    "\n",
    "    for i, axes in enumerate(fig_axes):\n",
    "        if i >= len(cct_names):\n",
    "            axes.axis('off')\n",
    "            continue\n",
    "        \n",
    "        y_name = cct_names[i]\n",
    "        Y = df[y_name].values\n",
    "        axes.plot(df['time'].values, Y, 'g', label=f\"ob\")\n",
    "        axes.set_ylabel(f'cct_{y_name}')\n",
    "        axes.set_xlabel(f'time(h)')\n",
    "\n",
    "        # axes.plot(df['time'].values, df[rates_names[i]].values, '+', label=f\"rate\")\n",
    "        \n",
    "        if dataset_pred:\n",
    "            _df_pred = dataset_pred.get_df()\n",
    "            t_eval = _df_pred['time'].values\n",
    "            axes.plot(t_eval, _df_pred[y_name].values, 'r', label=f\"c(t)\")\n",
    "        \n",
    "        \n",
    "        # axes.plot(t_eval, dcdt_df[y_name].values,'g', label=f\"c'(t)\")\n",
    "\n",
    "        axes.legend()\n",
    "        # axes.set_title(f\"{y_name}\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ed4460-3116-4895-a8dc-e98cb990e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dcdt_func(k_kinetics):\n",
    "    k_kinetics = np.array(k_kinetics).astype(np.uint8)\n",
    "    def _dcdt_func(t, c, p):\n",
    "        r1 = p.k1 * c.xN2 if k_kinetics[0] == 1 else p.k1\n",
    "        r2 = p.k2 * c.xNH3 if k_kinetics[1] == 1 else p.k2\n",
    "        r3 = p.k3 * c.xNO2 if k_kinetics[2] == 1 else p.k3\n",
    "        r4 = p.k4 * c.xNO3 if k_kinetics[3] == 1 else p.k4\n",
    "        r5 = p.k5 * c.xNO2 if k_kinetics[4] == 1 else p.k5\n",
    "        r6 = p.k6 * c.xNO2 * c.xNO3 if k_kinetics[5] == 1 else p.k6\n",
    "        r7 = p.k7 * c.xNO3 if k_kinetics[6] == 1 else p.k7\n",
    "        r8 = p.k8 * c.xNO3 if k_kinetics[7] == 1 else p.k8\n",
    "        r9 = p.k9 * c.xNH3 if k_kinetics[8] == 1 else p.k9\n",
    "        r10 = p.k10 * c.xNOrg if k_kinetics[9] == 1 else p.k10\n",
    "        r11 = p.k11 * c.xNOrg if k_kinetics[10] == 1 else p.k11\n",
    "\n",
    "        \n",
    "        dc_xNH3 = 2 * r1 + r7 + r10 - r2 - r6 - r9\n",
    "        dc_xNO3 = r3 - r7 - r4 - r8 + r11\n",
    "        dc_xNO2 = r2 + r4 - r3 - r6 - 2 * r5\n",
    "        dc_xNOrg = r8 + r9 - r10 - r11\n",
    "        dc_xN2 = r5 + r6 - r1\n",
    "\n",
    "        dc_ANH3 = (2 * r1 * (c.AN2 - c.ANH3) + (c.ANO3 - c.ANH3) * r7 + (c.ANOrg - c.ANH3) * r10) / c.xNH3\n",
    "        dc_ANO3 = ((c.ANO2 - c.ANO3) * r2 + (c.ANOrg - c.ANO3) * r11) / c.xNO3\n",
    "        dc_ANO2 = ((c.ANH3 - c.ANO2) * r2 + (c.ANO3 - c.ANO2) * r4) / c.xNO2\n",
    "        dc_ANOrg = ((c.ANO3 - c.ANOrg) * r8 + (c.ANH3 - c.ANOrg) * r9) / c.xNOrg\n",
    "        dc_AN2 = ((c.ANO2 - c.AN2) * r5 + (c.ANO2 * c.ANH3 - c.AN2) * r6) / c.xN2\n",
    "\n",
    "        # dcdts = [dc_xNH3, dc_xNO3, dc_xNO2, dc_xNOrg, dc_xN2, dc_ANH3, dc_ANO3, dc_ANO2, dc_ANOrg, dc_AN2]\n",
    "        \n",
    "        dcdts =  {\n",
    "            'xNH3': dc_xNH3,\n",
    "            'xNO3': dc_xNO3,\n",
    "            'xNO2': dc_xNO2,\n",
    "            'xNOrg': dc_xNOrg,\n",
    "            'xN2': dc_xN2,\n",
    "            'ANH3': dc_ANH3,\n",
    "            'ANO3': dc_ANO3,\n",
    "            'ANO2': dc_ANO2,\n",
    "            'ANOrg': dc_ANOrg,\n",
    "            'AN2': dc_AN2,\n",
    "        }\n",
    "        return dcdts\n",
    "    \n",
    "    return _dcdt_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f5b47f-98a5-44b5-808e-7fd8732237e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcdt_func_for_odeint(c, t, ks, k_kinetics):\n",
    "    \n",
    "    # print(c, t, ks, k_kinetics)\n",
    "    # print()\n",
    "    c_xNH3, c_xNO3, c_xNO2, c_xNOrg, c_xN2, c_ANH3, c_ANO3, c_ANO2, c_ANOrg, c_AN2 = c\n",
    "    \n",
    "    r1 = ks[0] * c_xN2 if k_kinetics[0] == 1 else ks[0]\n",
    "    r2 = ks[1] * c_xNH3 if k_kinetics[1] == 1 else ks[1]\n",
    "    r3 = ks[2] * c_xNO2 if k_kinetics[2] == 1 else ks[2]\n",
    "    r4 = ks[3] * c_xNO3 if k_kinetics[3] == 1 else ks[3]\n",
    "    r5 = ks[4] * c_xNO2 if k_kinetics[4] == 1 else ks[4]\n",
    "    r6 = ks[5] * c_xNO2 * c_xNO3 if k_kinetics[5] == 1 else ks[5]\n",
    "    r7 = ks[6] * c_xNO3 if k_kinetics[6] == 1 else ks[6]\n",
    "    r8 = ks[7] * c_xNO3 if k_kinetics[7] == 1 else ks[7]\n",
    "    r9 = ks[8] * c_xNH3 if k_kinetics[8] == 1 else ks[8]\n",
    "    r10 = ks[9] * c_xNOrg if k_kinetics[9] == 1 else ks[9]\n",
    "    r11 = ks[10] * c_xNOrg if k_kinetics[10] == 1 else ks[10]\n",
    "    \n",
    "    dc_xNH3 = 2 * r1 + r7 + r10 - r2 - r6 - r9\n",
    "    dc_xNO3 = r3 - r7 - r4 - r8 + r11\n",
    "    dc_xNO2 = r2 + r4 - r3 - r6 - 2 * r5\n",
    "    dc_xNOrg = r8 + r9 - r10 - r11\n",
    "    dc_xN2 = r5 + r6 - r1\n",
    "    dc_ANH3 = (2 * r1 * (c_AN2 - c_ANH3) + (c_ANO3 - c_ANH3) * r7 + (c_ANOrg - c_ANH3) * r10) / c_xNH3\n",
    "    dc_ANO3 = ((c_ANO2 - c_ANO3) * r2 + (c_ANOrg - c_ANO3) * r11) / c_xNO3\n",
    "    dc_ANO2 = ((c_ANH3 - c_ANO2) * r2 + (c_ANO3 - c_ANO2) * r4) / c_xNO2\n",
    "    dc_ANOrg = ((c_ANO3 - c_ANOrg) * r8 + (c_ANH3 - c_ANOrg) * r9) / c_xNOrg\n",
    "    dc_AN2 = ((c_ANO2 - c_AN2) * r5 + (c_ANO2 * c_ANH3 - c_AN2) * r6) / c_xN2\n",
    "\n",
    "    dcdts = [dc_xNH3, dc_xNO3, dc_xNO2, dc_xNOrg, dc_xN2, dc_ANH3, dc_ANO3, dc_ANO2, dc_ANOrg, dc_AN2]\n",
    "\n",
    "    return np.array(dcdts)\n",
    "\n",
    "# simulator function\n",
    "def competition_model(rng, t_eval, y0,  ks, k_kinetics, size=None):\n",
    "    # print(y0)\n",
    "    y = odeint(dcdt_func_for_odeint, y0=y0, t=t_eval, args=(ks, k_kinetics))\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ed351c-92ec-45f2-8bd5-b6163a4e0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_loss(pred, y):\n",
    "    r2_loss = 1 - np.square(pred - y).sum() / np.square(y - np.mean(y)).sum()\n",
    "    return r2_loss\n",
    "\n",
    "\n",
    "def get_model(dataset, k_kinetics, k_sigma_priors=0.01, kf_type=0):\n",
    "\n",
    "    df = dataset.get_df()\n",
    "    times = df['time'].values\n",
    "    \n",
    "    errors = dataset.get_errors()\n",
    "    rates = dataset.get_rates()\n",
    "    cct_names, error_names = dataset.get_var_col_names()\n",
    "        \n",
    "    # 定义参数优化模型\n",
    "    mcmc_model = pm.Model()\n",
    "    ## 参数个数\n",
    "    params_n = 11\n",
    "    parames ={}\n",
    "    \n",
    "    with mcmc_model:\n",
    "        for ki in range(1, params_n + 1):\n",
    "            if kf_type == 0:\n",
    "                p_dense = pm.HalfNormal(f\"k{ki}\", sigma=k_sigma_priors)\n",
    "            else:\n",
    "                p_dense = pm.Normal(f\"k{ki}\",mu=0, sigma=k_sigma_priors)\n",
    "            parames[f\"k{ki}\"] = (p_dense, ())\n",
    "    \n",
    "    # parames['k_kinetics'] = np.array(k_kinetics, dtype=np.float64)\n",
    "    parames['extra']=  np.zeros(1)\n",
    "    \n",
    "    c0 = {}\n",
    "    with mcmc_model:\n",
    "        for c_name in cct_names:\n",
    "            _maxx = df[c_name].values.max()\n",
    "            c0[f\"{c_name}\"] = (pm.HalfNormal(f\"{c_name}_s\", sigma=_maxx), ())\n",
    "            # c0[f\"{c_name}\"] = (pm.Normal(f\"{c_name}_s\", mu=_meanx, sigma=s), ())\n",
    "        \n",
    "    \n",
    "        y_hat, _, problem, solver, _, _ = sunode.wrappers.as_pytensor.solve_ivp(\n",
    "            y0=c0,\n",
    "            params=parames,\n",
    "            rhs=get_dcdt_func(k_kinetics),\n",
    "            tvals=times,\n",
    "            t0=times[0],\n",
    "        )\n",
    "        \n",
    "        sd = pm.HalfNormal('sd')\n",
    "        for c_name in cct_names:\n",
    "            pm.Normal(f'{c_name}', mu=y_hat[f\"{c_name}\"], sigma=sd, observed=df[f\"{c_name}\"].values)\n",
    "            pm.Deterministic(f'{c_name}_mu', y_hat[f\"{c_name}\"])\n",
    "\n",
    "    return mcmc_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44b24281-7e43-4551-ae61-5a81bb77870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_ks(idata_sum):\n",
    "    parames_summary = az.summary(idata, round_to=10)\n",
    "    ks_names = [f\"k{x+1}\" for x in range(11)]\n",
    "\n",
    "    predict_ks = []\n",
    "    for k_name in ks_names:\n",
    "        k_v = parames_summary[\"mean\"][k_name]\n",
    "        predict_ks.append(k_v)\n",
    "    return np.array(predict_ks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45e21d13-e53f-41f4-bda0-aa9d7f4350b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(dataset, idata_sum):\n",
    "    res_df = idata_sum\n",
    "    \n",
    "    predict_ks = get_predict_ks(idata_sum=idata_sum)\n",
    "    \n",
    "\n",
    "    df = dataset.get_df()\n",
    "    times = df['time'].values\n",
    "    \n",
    "    errors = dataset.get_errors()\n",
    "    rates = dataset.get_rates()\n",
    "    cct_names, error_names = dataset.get_var_col_names()\n",
    "    \n",
    "    \n",
    "    \n",
    "    predict_start = []\n",
    "    \n",
    "    for c_name in cct_names:\n",
    "        _x = res_df['mean'][f'{c_name}_s']\n",
    "        predict_start.append(_x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    c_df = pd.DataFrame(columns=cct_names)\n",
    "    t_n = len(times)\n",
    "    for c_name in cct_names:\n",
    "        c_value = []\n",
    "        for i in range(t_n):\n",
    "            _x = res_df['mean'][f\"{c_name}_mu[{i}]\"]\n",
    "            c_value.append(_x)\n",
    "        c_df[c_name] = c_value\n",
    "    \n",
    "    return predict_ks, predict_start, c_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29406f27-1b18-48db-b15d-fc9a238847ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k10,k_kinetics,xNH3_r2,xNO3_r2,xNO2_r2,xNOrg_r2,xN2_r2,ANH3_r2,ANO3_r2,ANO2_r2,ANOrg_r2,AN2_r2,r2_mean,r2_all'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "res_path_list = glob.glob(\"save_idata/*\")\n",
    "dataset = MyDataset(\"dataset/data.csv\")\n",
    "df = dataset.get_df()\n",
    "cct_names, error_names = dataset.get_var_col_names()\n",
    "\n",
    "\n",
    "title_str = \"k10,k_kinetics\"\n",
    "\n",
    "for c_name in cct_names:\n",
    "    title_str += f\",{c_name}_r2\"\n",
    "    \n",
    "title_str += \",r2_mean,r2_all\"\n",
    "\n",
    "print(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fd4f2-2238-44b7-b8e3-f39c0dd005bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "\n",
    "res_path_list = glob.glob(\"save_idata/*\")\n",
    "dataset = MyDataset(\"dataset/data.csv\")\n",
    "df = dataset.get_df()\n",
    "cct_names, error_names = dataset.get_var_col_names()\n",
    "\n",
    "res_csv = open(\"res_r2.csv\", 'w+', encoding=\"utf8\")\n",
    "\n",
    "title_str = \"k10,k_kinetics\"\n",
    "\n",
    "for c_name in cct_names:\n",
    "    title_str += f\",{c_name}_r2\"\n",
    "    \n",
    "title_str += \",r2_mean,r2_all\"\n",
    "res_csv.write(f\"{title_str}\\n\")\n",
    "\n",
    "\n",
    "for index, res_file_path in enumerate(res_path_list):\n",
    "    \n",
    "    print(f\"{index+1}/{len(res_path_list)} {res_file_path}\")\n",
    "    \n",
    "    line_str = \"\"\n",
    "    \n",
    "    k_10 = os.path.basename(res_file_path).split('-')[0]\n",
    "    k_10_2 = bin(int(k_10))[2:]\n",
    "    k_kinetics = f\"{k_10_2:0>11}\"\n",
    "    \n",
    "    line_str += f\"{k_10},{k_kinetics}\"\n",
    "    \n",
    "    f_size = os.path.getsize(res_file_path)\n",
    "    if f_size<1:\n",
    "        continue\n",
    "    \n",
    "    idata = pickle.load(open(res_file_path, 'rb'))\n",
    "    idata_sum = az.summary(idata, round_to=10)\n",
    "    \n",
    "    predict_ks, predict_start, c_df = get_result(dataset, idata_sum)\n",
    "    \n",
    "    r2_losses = []\n",
    "    for cct_name in cct_names:\n",
    "        _l = r2_loss(df[cct_name],c_df[cct_name])\n",
    "        line_str += f\",{_l}\"\n",
    "        r2_losses.append(_l)\n",
    "    \n",
    "    r2_all = r2_loss(df[cct_names].values, c_df.values)\n",
    "    r2_mean = np.array(r2_losses).mean()\n",
    "    line_str += f\",{r2_mean}, {r2_all}\"\n",
    "    res_csv.write(f\"{line_str}\\n\")\n",
    "\n",
    "res_csv.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymcmain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbd2c194b49ea80345e8ea18e3a6000c76ee140cf13f4f15affb9019c7957e43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
